<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="SuctionPrompt">
    <link rel="shortcut icon" href="../favicon/favicon_suctionprompt.ico">
    <title>Slide-Support</title>
    <style>
        @import url('https://fonts.googleapis.com/css?family=Noto+Sans+JP');
        a {
            color: #4169e1;
        }
        p {
            font-family: 'Noto Sans JP', sans-serif;
            line-height:30px;
            font-size:16px;
        }
        body {
            font:'Noto Sans JP', sans-serif;
            margin: 0;
            padding: 0;
            background-color: #f4f4f4;
        }
        header {
            background-color: #333;
            color: white;
            padding: 1rem;
            text-align: center;
        }
        nav {
            text-align: center;
            margin-top: 1rem;
        }
        nav a {
            margin: 0 15px;
            text-decoration: none;
            color: #333;
        }
        section {
            padding: 20px;
            background-color: white;
            margin: 20px auto;
            width: 75%;
            max-width: 1000px;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        }
        footer {
            text-align: center;
            padding: 1rem;
            background-color: #333;
            color: white;
            margin-top: 20px;
        }
    </style>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-RVFZ9VYXRM"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-RVFZ9VYXRM');
    </script>
</head>
    
<header>
    <h1>Probabilistic Slide-support Manipulation Planning in Clutter</h1>
    <p><a href="https://nagato710.github.io/profile/">Shusei Nagato</a>, <a href="https://tomohiromotoda.github.io/" target="_blank">Tomohiro Motoda</a>, Takao Nishi, Petit Damien, 
        <br>Takuya Kiyokawa, Weiwei Wan, and Kensuke Harada, 
        <br>IEEE IROS2023</p>

    <p>
        <span>[<a href="https://arxiv.org/abs/2306.12649" target="_blank" el="enoopener">ArXiv</a>]</span>
        <span>[<a href="https://www.youtube.com/watch?v=Qyes4hjCP3w&feature=youtu.be" target="_blank" el="noopener">YouTube</a>]</span>
    </p>
</header>

<div class="youtube" style="text-align: center">
    <br>
    <iframe width="600" height="315" src="https://www.youtube.com/embed/Qyes4hjCP3w" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
</div>

<section id="about">
    <h3 style="text-align: center">Abstract</h3>
    <p>
        To safely and efficiently extract an object from the clutter, 
        this paper presents a bimanual manipulation planner in which one hand of the robot is used 
        to slide the target object out of the clutter while the other hand is used 
        to support the surrounding objects to prevent the clutter from collapsing.
    </p>
</section>

    <body id="page">
        <article>
            <section id="main">
                    <div class="container" style="text-align: center">
                    <div style="text-align: center">
                        <p>
                            Our method uses a neural network to predict the physical phenomena of the clutter when the target object is moved. 
                            We generate the most efficient action based on the Monte Carlo tree search.  
                        </p>
                        <img src="img/2023-iros-top.png" alt="top image"  width=98%;>
                        
                    </div>

                    <br> 

                    <div style="text-align: center">
                        <p>
                            The grasping and sliding actions are planned to minimize the number of motion sequences to pick the target object.
                            Experiments with a real bimanual robot confirmed that the robot could retrieve the target object, 
                            reducing the total number of motion sequences and improving safety.
                        </p>
                        <img src="img/2023-iros-exp.png" alt="top image"  width=98%;>             
                    </div>
                </section>
        </article>

        <footer>
            <p>&copy; 2024 Tomohiro Motoda All rights reserved.</p>
        </footer>
    </body>
</html>
